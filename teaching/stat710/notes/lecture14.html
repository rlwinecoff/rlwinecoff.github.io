<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="http://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script src="http://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div id="lecture-14-fitting-probability-models" class="slide section level2">
<h1>Lecture 14: Fitting probability models</h1>
<p>Today: Transitioning away from R/software engineering, towards algorithms for statistics</p>
<p>Agenda</p>
<ul>
<li><p>Probability review</p></li>
<li><p>Distributions in R</p></li>
<li><p>Methods for fitting distributions</p></li>
</ul>
</div>
<div id="logistics" class="slide section level2">
<h1>Logistics</h1>
<p>Final project</p>
<ul>
<li><p>I will post this weekend and send an email or announcement</p></li>
<li><p>Can be done individually or in teams of up to 3</p></li>
<li><p>If you want to do the project, email me by Friday, March 8, with your group. (No switching between final exam and final project at the last minute.)</p></li>
<li><p>Office hours cut short today, I need to leave at 3:45.</p></li>
</ul>
</div>
<div id="very-short-review-of-probability" class="slide section level2">
<h1>Very short review of probability</h1>
<p>We need to know about <em>random variables</em> and their distributions.</p>
</div>
<div class="slide section level2">

<p>What is a random variable?</p>
<ul>
<li><p>Very formally: a function from a state space to the real numbers</p></li>
<li><p>Less formally: Think about random variables as describing the outcome of an experiment</p></li>
</ul>
</div>
<div class="slide section level2">

<p>In R, you can draw a random variable from a distribution with functions of the form <code>rdist</code>.</p>
<ul>
<li><p><code>rnorm</code> draws a random variable from a normal distribution.</p></li>
<li><p><code>rbinom</code> draws a random variable from a binomial distribution</p></li>
<li><p><code>rpois</code> draws a random variable from a Poisson distribution</p></li>
</ul>
<p>... and so on</p>
<div class="incremental">
<p>Syntax is <code>rdist(n, param1, param2,..., paramn)</code></p>
<ul>
<li><p><code>n</code> is the number of random variables to draw from the distribution.</p></li>
<li><p><code>param1</code>, ..., <code>paramn</code> are the parameters of the distribution (e.g. mean and standard deviation for the normal, mean for the Poisson, probability of success for the binomial)</p></li>
</ul>
</div>
</div>
<div class="slide section level2">

<div class="incremental">
<p>Examples</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">10</span>, <span class="dt">mean =</span> <span class="dv">5</span>, <span class="dt">sd =</span> .<span class="dv">1</span>)</code></pre>
<pre><code>##  [1] 5.095750 5.116174 5.074507 5.180313 5.136851 5.014525 5.077125
##  [8] 5.036322 4.946439 5.057097</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">5</span>, <span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">prob =</span> .<span class="dv">8</span>)</code></pre>
<pre><code>## [1] 4 5 4 5 4</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rpois</span>(<span class="dt">n =</span> <span class="dv">20</span>, <span class="dt">lambda =</span> <span class="dv">10</span>)</code></pre>
<pre><code>##  [1]  8  5 13 15  7  6  4 13 12 14  8 11 12  8 10  9 11 12 13  7</code></pre>
</div>
</div>
<div class="slide section level2">

<p>A random variable is characterized by its <em>cumulative distribution function</em> (CDF).</p>
<ul>
<li><p>Measures the probability that the random variable takes a value at most <span class="math">\(x\)</span>.</p></li>
<li><p>If <span class="math">\(F_X\)</span> is the cumulative distribution function for a random variable <span class="math">\(X\)</span>, <span class="math">\(F_X(x) = P(X \le x)\)</span>.</p></li>
<li><p>Can get all the other information you need about the random variable from this function (e.g. probability it lies above a certain value, probability it lies in an interval, probability it lies in other sets)</p></li>
</ul>
</div>
<div class="slide section level2">

<p>In R, the cumulative distribution functions for common distributions are available as <code>pdist</code>, so</p>
<ul>
<li><p><code>pnorm</code> gives the cumulative distribution function for a normal distribution.</p></li>
<li><p><code>pbinom</code> gives the cumulative distribution function for a binomial distribution.</p></li>
<li><p><code>ppois</code> gives the cumulative distribution function for a Poisson distribution.</p></li>
</ul>
<div class="incremental">
<p>Syntax is <code>pdist(q, param1, ..., paramn)</code></p>
<ul>
<li><p>Returns <span class="math">\(F_X(q)\)</span>, if <span class="math">\(F_X\)</span> is the cumulative distribution function for a random variable <span class="math">\(X\)</span> following distribution <code>dist</code></p></li>
<li><p><code>param1</code>, ..., <code>paramn</code> are the parameters of the distribution</p></li>
</ul>
</div>
</div>
<div class="slide section level2">

<div class="incremental">
<p>For example:</p>
</div>
<div class="incremental">
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="dt">q =</span> <span class="dv">0</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</code></pre>
<pre><code>## [1] 0.5</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pbinom</span>(<span class="dt">q =</span> .<span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">prob =</span> .<span class="dv">2</span>)</code></pre>
<pre><code>## [1] 0.8</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pbinom</span>(<span class="dt">q =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">prob =</span> .<span class="dv">2</span>)</code></pre>
<pre><code>## [1] 1</code></pre>
</div>
</div>
<div class="slide section level2">

<p>Normal CDF:</p>
<pre class="sourceCode r"><code class="sourceCode r">qvec =<span class="st"> </span><span class="kw">seq</span>(-<span class="dv">3</span>, <span class="dv">3</span>, <span class="dt">length.out =</span> <span class="dv">1000</span>)
Fx =<span class="st"> </span><span class="kw">sapply</span>(qvec, pnorm, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)
<span class="kw">plot</span>(Fx ~<span class="st"> </span>qvec, <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>)</code></pre>
<div class="figure">
<img src="lecture-14-fig/unnamed-chunk-3-1.png" />
</div>
</div>
<div class="slide section level2">

<p>Binomial CDF:</p>
<pre class="sourceCode r"><code class="sourceCode r">qvec =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">1001</span>)
Fx =<span class="st"> </span><span class="kw">sapply</span>(qvec, pbinom, <span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">p =</span> .<span class="dv">5</span>)
<span class="kw">plot</span>(Fx ~<span class="st"> </span>qvec, <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>)</code></pre>
<div class="figure">
<img src="lecture-14-fig/unnamed-chunk-4-1.png" />
</div>
</div>
<div class="slide section level2">

<p>Remember that <code>rdist</code> draws random variables from <code>dist</code>, and <code>pdist(q)</code> computes the probability that a random variable with distribution <code>dist</code> takes a value less than or equal to q?</p>
<div class="incremental">
<p>Let's check:</p>
<pre class="sourceCode r"><code class="sourceCode r">## draw 100 random variables from a normal with mean 0 and sd 1
x =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">1000</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)
## compute what fraction of the random variables are at most -.5
q =<span class="st"> </span>-.<span class="dv">5</span>
<span class="kw">mean</span>(x &lt;=<span class="st"> </span>q)</code></pre>
<pre><code>## [1] 0.33</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## compute what fraction of the time the random variables should be less than or equal to -.5
<span class="kw">pnorm</span>(<span class="dt">q =</span> q, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</code></pre>
<pre><code>## [1] 0.3085375</code></pre>
<p>Not exactly the same, but pretty close!</p>
</div>
</div>
<div class="slide section level2">

<div class="incremental">
<pre class="sourceCode r"><code class="sourceCode r">## try again with a binomial distribution
x =<span class="st"> </span><span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">1000</span>, <span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">prob =</span> .<span class="dv">2</span>)
## compute what fraction of the random variables are 1 or less
q =<span class="st"> </span><span class="dv">1</span>
<span class="kw">mean</span>(x &lt;=<span class="st"> </span>q)</code></pre>
<pre><code>## [1] 0.742</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## compute what fraction of the time the random variables should be 1 or less
<span class="kw">pbinom</span>(<span class="dt">q =</span> q, <span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">prob =</span> .<span class="dv">2</span>)</code></pre>
<pre><code>## [1] 0.73728</code></pre>
<p>Again, pretty close! You can check for other values of q and other distributions.</p>
</div>
</div>
<div class="slide section level2">

<p>Final concept: probability mass functions and probability density functions</p>
<ul>
<li><p>Probability mass functions describe <em>discrete</em> radom variables</p></li>
<li><p>Probability density functions describe <em>continuous</em> random variables</p></li>
</ul>
</div>
<div class="slide section level2">

<p>Discrete random variables:</p>
<ul>
<li><p>The random variable can take on either a finite number of values or a countable number of values</p></li>
<li><p>For example: binomial random variable with size <span class="math">\(n\)</span> and probability <span class="math">\(p\)</span> can take values <span class="math">\(0, 1, 2, \ldots, n\)</span></p></li>
<li><p>For example: A Poisson random variable can take values <span class="math">\(0, 1, 2,\ldots\)</span></p></li>
<li><p>If <span class="math">\(X\)</span> is a discrete random variable, there are some values <span class="math">\(x\)</span> for which <span class="math">\(P(X = x) &gt; 0\)</span>.</p></li>
</ul>
</div>
<div class="slide section level2">

<p>Definition of probability mass function: If <span class="math">\(f_X\)</span> is the probability mass function for a random variable <span class="math">\(X\)</span>, <span class="math">\(f_X(x) = P(X = x)\)</span>.</p>
<div class="incremental">
<p>In R: probability mass functions for common distributions are given by functions of the form <code>ddist</code>.</p>
<p>Syntax: <code>ddist(x, param1, ..., paramn)</code> computes <span class="math">\(f_X(x)\)</span> for the a random variable <span class="math">\(X\)</span> following distribution <code>dist</code> with parameters <code>param1</code>, ..., <code>paramn</code></p>
</div>
</div>
<div class="slide section level2">

<div class="incremental">
<p>For example:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">prob =</span> .<span class="dv">5</span>)</code></pre>
<pre><code>## [1] 0.5</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dt">x =</span> <span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">prob =</span> .<span class="dv">5</span>)</code></pre>
<pre><code>## [1] 0.25</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dt">x =</span> .<span class="dv">5</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">prob =</span> .<span class="dv">5</span>)</code></pre>
<pre><code>## Warning in dbinom(x = 0.5, size = 2, prob = 0.5): non-integer x = 0.500000</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
</div>
<div class="slide section level2">

<pre class="sourceCode r"><code class="sourceCode r">x_vec =<span class="st"> </span><span class="dv">0</span>:<span class="dv">2</span>
fx =<span class="st"> </span><span class="kw">sapply</span>(x_vec, dbinom, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">prob =</span> .<span class="dv">5</span>)
<span class="kw">plot</span>(fx ~<span class="st"> </span>x_vec, <span class="dt">type =</span> <span class="st">&#39;h&#39;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, .<span class="dv">5</span>))</code></pre>
<div class="figure">
<img src="lecture-14-fig/unnamed-chunk-8-1.png" />
</div>
</div>
<div class="slide section level2">

<pre class="sourceCode r"><code class="sourceCode r">x_vec =<span class="st"> </span><span class="dv">0</span>:<span class="dv">5</span>
fx =<span class="st"> </span><span class="kw">sapply</span>(x_vec, dbinom, <span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">prob =</span> .<span class="dv">8</span>)
<span class="kw">plot</span>(fx ~<span class="st"> </span>x_vec, <span class="dt">type =</span> <span class="st">&#39;h&#39;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, .<span class="dv">5</span>))</code></pre>
<div class="figure">
<img src="lecture-14-fig/unnamed-chunk-9-1.png" />
</div>
</div>
<div class="slide section level2">

<div class="incremental">
<p>As before, we can check that our definitions are consistent:</p>
<pre class="sourceCode r"><code class="sourceCode r">## generate random variables from a binomial distribution with size = 2 and prob = .5
X =<span class="st"> </span><span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">1000</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">prob =</span> .<span class="dv">5</span>)
<span class="kw">head</span>(X)</code></pre>
<pre><code>## [1] 2 1 2 1 1 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## compute the fraction of the random variables that took value exactly equal to 1
x =<span class="st"> </span><span class="dv">2</span>
<span class="kw">mean</span>(X ==<span class="st"> </span>x)</code></pre>
<pre><code>## [1] 0.246</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## compute the pmf for the distribution at x = 1
<span class="kw">dbinom</span>(<span class="dt">x =</span> x, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">prob =</span> .<span class="dv">5</span>)</code></pre>
<pre><code>## [1] 0.25</code></pre>
<p>Apologies for the notation, but the norm is to denote random variables by capital letters and to denote the actual values they take by lower-case letters.</p>
<p>You'll often see things like <span class="math">\(P(X = x)\)</span>, which means the probability that a random variable <span class="math">\(X\)</span> takes value <span class="math">\(x\)</span>.</p>
</div>
</div>
<div class="slide section level2">

<p>Continuous random variables:</p>
<ul>
<li><p>Formally: A random variable whose cumulative distribution function is continuous.</p></li>
<li><p>You can think of this as random variables that can take values either on the entire real line, or on subsets of the real line.</p></li>
<li><p>For example: normal distribution, gamma distribution</p></li>
<li><p>In contrast to discrete random variables, if <span class="math">\(X\)</span> is a continuous random variable, there are no values <span class="math">\(x\)</span> for which <span class="math">\(P(X = x) &gt; 0\)</span>.</p></li>
<li><p>Because of this, we can't define a probability mass function the way we did for discrete random variables, we have to do something else, and that something else is a probability density function.</p></li>
</ul>
</div>
<div class="slide section level2">

<p>Probability density function formally: If <span class="math">\(X\)</span> is a continuous random variable with cumulative distribution function <span class="math">\(F_X\)</span>, the probability density function of <span class="math">\(X\)</span>, <span class="math">\(f_X(x)\)</span>, is defined as <span class="math">\(f_X(x) = F_X&#39;(x)\)</span>.</p>
<div class="incremental">
<p>Think of as analogous to probability mass functions</p>
<ul>
<li><p><span class="math">\(P(X = x) = 0\)</span> for continuous random variables, but...</p></li>
<li><p>The random variable <span class="math">\(X\)</span> is more likely to take on values close to <span class="math">\(x\)</span> if <span class="math">\(f_X(x)\)</span> is large than if <span class="math">\(f_X(x)\)</span> is small.</p></li>
</ul>
</div>
</div>
<div class="slide section level2">

<p>In R: probability density functions for common distributions are given by functions of the form <code>ddist</code> (the same as for probability mass functions)</p>
<p>Syntax: <code>ddist(x, param1, ..., paramn)</code> computes <span class="math">\(f_X(x)\)</span> for the a random variable <span class="math">\(X\)</span> following distribution <code>dist</code> with parameters <code>param1</code>, ..., <code>paramn</code></p>
</div>
<div class="slide section level2">

<div class="incremental">
<p>For example:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dnorm</span>(<span class="dt">x =</span> <span class="dv">0</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</code></pre>
<pre><code>## [1] 0.3989423</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dnorm</span>(<span class="dt">x =</span> <span class="dv">1</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</code></pre>
<pre><code>## [1] 0.2419707</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dnorm</span>(<span class="dt">x =</span> <span class="dv">50</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
</div>
<div class="slide section level2">

<pre class="sourceCode r"><code class="sourceCode r">x_vec =<span class="st"> </span><span class="kw">seq</span>(-<span class="dv">3</span>, <span class="dv">3</span>, <span class="dt">length.out =</span> <span class="dv">1000</span>)
fx =<span class="st"> </span><span class="kw">sapply</span>(x_vec, dnorm, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)
<span class="kw">plot</span>(fx ~<span class="st"> </span>x_vec, <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>)</code></pre>
<div class="figure">
<img src="lecture-14-fig/unnamed-chunk-12-1.png" />
</div>
</div>
<div id="summing-up-probability" class="slide section level2">
<h1>Summing up: probability</h1>
<ul>
<li><p>Random variables are like normal variables, but the values they take are random</p></li>
<li><p>If <span class="math">\(F_X\)</span> is the cumulative distribution function for a random variable <span class="math">\(X\)</span>, <span class="math">\(F_X(x)\)</span> gives <span class="math">\(P(X \le x)\)</span>, and characterizes the distribution.</p></li>
<li><p>If <span class="math">\(f_X\)</span> is the probability density or probability mass function for a random variable <span class="math">\(X\)</span>, <span class="math">\(f_X(x)\)</span> large means that <span class="math">\(X\)</span> is more likely to take values exactly equal to <span class="math">\(x\)</span> (for discrete random variables) or close to <span class="math">\(x\)</span> (for continuous random variables).</p></li>
</ul>
</div>
<div id="fitting-probability-models-to-data" class="slide section level2">
<h1>Fitting probability models to data</h1>
<p>Setup: We have a set of data points <span class="math">\(x_1, \ldots, x_n\)</span>, and we want to find a probability distribution that describes the data well.</p>
<div class="incremental">
<p>Why do we want to do this?</p>
<ul>
<li><p>We are interested in the parameters</p></li>
<li><p>Data compression</p></li>
<li><p>Uncertainty quantification</p></li>
</ul>
</div>
</div>
<div id="how-do-we-fit-probability-models" class="slide section level2">
<h1>How do we fit probability models?</h1>
<p>Two main strategies:</p>
<ul>
<li><p>Maximum likelihood</p></li>
<li><p>Method of moments</p></li>
<li><p>Many variations on these themes</p></li>
</ul>
</div>
<div id="maximum-likelihood" class="slide section level2">
<h1>Maximum likelihood</h1>
<p>Problem: We have a family of probability distributions, indexed by a parameter <span class="math">\(\theta\)</span>, and we need to choose one to describe the data.</p>
<p>Solution, heuristically:</p>
<ul>
<li><p>Assume that our data <span class="math">\(x_1, \ldots, x_n\)</span> are realizations of independent random variables <span class="math">\(X_1, \ldots, X_n\)</span>, each coming from the same distribution with parameter <span class="math">\(\theta\)</span>.</p></li>
<li><p>Find the value of <span class="math">\(\theta\)</span> that makes the data most likely.</p></li>
<li><p>Use either the probability density (continuous random variables) or probability mass (discrete random variables) to describe how likely the data is for a given value of the parameter <span class="math">\(\theta\)</span>.</p></li>
</ul>
</div>
<div class="slide section level2">

<p>Formally:</p>
<ul>
<li><p>Let <span class="math">\(f(x; \theta)\)</span> be the probability density function or probability mass function of a random variable with drawn from a distribution with parameter <span class="math">\(\theta\)</span>.</p></li>
<li><p>With independent data points <span class="math">\(x_1\)</span>, <span class="math">\(x_2\)</span>, <span class="math">\(x_n\)</span>, the likelihood is</p></li>
</ul>
<p><span class="math">\[
L(\theta)=\prod_{i=1}^n f(x_i;\theta)
\]</span></p>
<div class="incremental">
<p>Recall that the probability density/mass function describes how likely a random variable is to take a given value.</p>
<ul>
<li><p>If <span class="math">\(f(x_i; \theta)\)</span> is high, it is very likely that we would see the value <span class="math">\(x_i\)</span> if <span class="math">\(x_i\)</span> really came from a distribution with parameter <span class="math">\(\theta\)</span></p></li>
<li><p>If <span class="math">\(f(x_i; \theta)\)</span> is low, it is unlikely that we would see the value <span class="math">\(x_i\)</span> if <span class="math">\(x_i\)</span> really came from a distribution with parameter <span class="math">\(\theta\)</span></p></li>
</ul>
<p>Therefore: find the value of <span class="math">\(\theta\)</span> that maximizes the likelihood.</p>
</div>
</div>
<div class="slide section level2">

<p>In practice, we work with the log likelihood instead of the likelihood:</p>
<p><span class="math">\[
\ell(\theta) = \sum_{i=1}^n \log f(x_i; \theta)
\]</span></p>
<ul>
<li><p>Easier to work with analytically</p></li>
<li><p>Better computationally because multiplying lots of small numbers together is bad (if you have a lot of data points you can get within machine tolerance of 0).</p></li>
</ul>
</div>
<div class="slide section level2">

<p>For example: we have data points <span class="math">\(x_1, \ldots, x_n\)</span>, and we want to find the <span class="math">\(N(\theta, 1)\)</span> distribution that fits the data the best.</p>
<div class="incremental">
<p>The likelihood is <span class="math">\[
L(x;  \theta) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi}}\exp((x_i - \theta)^2)
\]</span></p>
<p>and the log likelihood is <span class="math">\[
\ell(x;  \theta) = \sum_{i=1}^n\log \left( \frac{1}{\sqrt{2\pi}}\exp((x_i - \theta)^2) \right)
\]</span></p>
</div>
</div>
<div class="slide section level2">

<p>We can use <code>dnorm</code> in R to compute the log likelihood for any <span class="math">\(x\)</span> and <span class="math">\(\theta\)</span> we want:</p>
<pre class="sourceCode r"><code class="sourceCode r">## create a function that computes the log likelihood
likelihood =<span class="st"> </span>function(theta, x) {
    <span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean =</span> theta, <span class="dt">sd =</span> <span class="dv">1</span>)))
}
x =<span class="st"> </span><span class="kw">c</span>(<span class="fl">5.5</span>, <span class="dv">4</span>, <span class="fl">3.2</span>, <span class="fl">4.7</span>, <span class="fl">4.3</span>, <span class="fl">3.5</span>)
theta_vec =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dt">length.out =</span> <span class="dv">100</span>)
l_of_theta =<span class="st"> </span><span class="kw">sapply</span>(theta_vec, likelihood, x)
<span class="kw">plot</span>(l_of_theta ~<span class="st"> </span>theta_vec, <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>)</code></pre>
<div class="figure">
<img src="lecture-14-fig/unnamed-chunk-13-1.png" />
</div>
</div>
<div class="slide section level2">

<p>What is the maximum?</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(l_of_theta ~<span class="st"> </span>theta_vec, <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">mean</span>(x))</code></pre>
<div class="figure">
<img src="lecture-14-fig/unnamed-chunk-14-1.png" />
</div>
</div>
<div class="slide section level2">

<p>Alternately, just search over the grid:</p>
<pre class="sourceCode r"><code class="sourceCode r">max_idx =<span class="st"> </span><span class="kw">which.max</span>(l_of_theta)
theta_vec[max_idx]</code></pre>
<pre><code>## [1] 4.242424</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## compare with
<span class="kw">mean</span>(x)</code></pre>
<pre><code>## [1] 4.2</code></pre>
</div>
<div class="slide section level2">

<p>Another example: Binomial, five trials, unknown success probability.</p>
<pre class="sourceCode r"><code class="sourceCode r">likelihood =<span class="st"> </span>function(theta, x) {
    <span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dbinom</span>(<span class="dt">x =</span> x, <span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">prob =</span> theta)))
}</code></pre>
</div>
<div class="slide section level2">

<p>Compute the likelihoods for many possible values of <code>prob</code></p>
<pre class="sourceCode r"><code class="sourceCode r">x =<span class="st"> </span><span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">prob =</span> .<span class="dv">2</span>)
theta_vec =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> <span class="dv">100</span>)
log_likelihoods =<span class="st"> </span><span class="kw">sapply</span>(theta_vec, likelihood, x)
<span class="kw">plot</span>(log_likelihoods ~<span class="st"> </span>theta_vec, <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> .<span class="dv">2</span>)</code></pre>
<div class="figure">
<img src="lecture-14-fig/unnamed-chunk-17-1.png" />
</div>
</div>
<div class="slide section level2">

<p>We see that the maximum is pretty close to the true value, <span class="math">\(.2\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">max_idx =<span class="st"> </span><span class="kw">which.max</span>(log_likelihoods)
theta_vec[max_idx]</code></pre>
<pre><code>## [1] 0.2121212</code></pre>
</div>
<div id="summing-up" class="slide section level2">
<h1>Summing up</h1>
<ul>
<li><p>Fitting probability distributions just means finding the one that &quot;looks&quot; the most like your data, according to some measure.</p></li>
<li><p>For all but very simple cases where we can get closed-form solutions with pen and paper, we need more computational tools to fit these distributions.</p></li>
</ul>
</div>
</body>
</html>
