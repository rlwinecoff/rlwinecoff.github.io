<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="http://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script src="http://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div id="applications-and-cvx" class="slide section level2">
<h1>Applications and cvx</h1>
<p>Agenda today</p>
<ul>
<li><p>cvx, package for fitting convex problems in general</p></li>
<li><p>Optimization applications in statistics</p></li>
</ul>
</div>
<div id="defining-an-optimization-problem-in-cvx" class="slide section level2">
<h1>Defining an optimization problem in cvx</h1>
<p>Remember how we defined a convex optimization problem:</p>
<p><span class="math">\[
\begin{align*}
\text{minimize} \quad &amp;f_0(x) \\
\text{subject to}\quad &amp;f_i(x) \le 0, \quad i = 1,\ldots, m\\
&amp;a_j^T x = b_j, \quad j = 1,\ldots, n
\end{align*}
\]</span></p>
<p>Components:</p>
<ul>
<li><p>Variables to minimize over (<span class="math">\(x\)</span> in the formulation above, can be multi-dimensional)</p></li>
<li><p>Objective function (<span class="math">\(f_0\)</span> above, what we want to minimize)</p></li>
<li><p>Constraints on the variables</p></li>
</ul>
<p>In the cvx package, we define these three components, create a problem out of them, and the solver will do the rest.</p>
</div>
<div id="example" class="slide section level2">
<h1>Example</h1>
<p>For example, suppose our problem is: <span class="math">\[
\begin{align*}
\text{minimize}_{x, y} \quad &amp;x^2 + y^2 \\
\text{subject to} \quad &amp;x \ge 0\\
&amp; 2x + y = 1
\end{align*}
\]</span></p>
<p>How do we set this up in cvx/R?</p>
</div>
<div class="slide section level2">

<p>Define the variables to be minimized over:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(CVXR)
<span class="co"># Variables minimized over</span>
x =<span class="st"> </span><span class="kw">Variable</span>(<span class="dv">1</span>)
y =<span class="st"> </span><span class="kw">Variable</span>(<span class="dv">1</span>)
x</code></pre>
<pre><code>## Variable(1, 1)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(x)</code></pre>
<pre><code>## [1] &quot;Variable&quot;
## attr(,&quot;package&quot;)
## [1] &quot;CVXR&quot;</code></pre>
</div>
<div class="slide section level2">

<p>Define the objective function:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The function we want to minimize</span>
objective =<span class="st"> </span><span class="kw">Minimize</span>(x^<span class="dv">2</span> +<span class="st"> </span>y^<span class="dv">2</span>)
objective</code></pre>
<pre><code>## An object of class &quot;Minimize&quot;
## Slot &quot;expr&quot;:
## AddExpression(c(&quot;Expression(CONVEX, POSITIVE, 1)&quot;, &quot;Expression(CONVEX, POSITIVE, 1)&quot;), c(&quot;Expression(CONVEX, POSITIVE, 1)&quot;, &quot;Expression(CONVEX, POSITIVE, 1)&quot;))</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(objective)</code></pre>
<pre><code>## [1] &quot;Minimize&quot;
## attr(,&quot;package&quot;)
## [1] &quot;CVXR&quot;</code></pre>
</div>
<div class="slide section level2">

<p>Define the constraints:</p>
<pre class="sourceCode r"><code class="sourceCode r">## The constraints
constraints =<span class="st"> </span><span class="kw">list</span>(x &gt;=<span class="st"> </span><span class="dv">0</span>, <span class="dv">2</span>*x +<span class="st"> </span>y ==<span class="st"> </span><span class="dv">1</span>)
constraints</code></pre>
<pre><code>## [[1]]
## LeqConstraint(Constant(CONSTANT, ZERO, (1,1)), Variable(1, 1))
## [[2]]
## EqConstraint(Expression(AFFINE, UNKNOWN, 1), Expression(AFFINE, UNKNOWN, 1), Constant(CONSTANT, POSITIVE, (1,1)))</code></pre>
</div>
<div class="slide section level2">

<p>The optimization problem is then composed of the objective and the constraints:</p>
<pre class="sourceCode r"><code class="sourceCode r">## Problem definition
prob &lt;-<span class="st"> </span><span class="kw">Problem</span>(objective, constraints)</code></pre>
</div>
<div class="slide section level2">

<p>To perform the optimization we use <code>solve(problem)</code></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Problem solution</span>
solution =<span class="st"> </span><span class="kw">solve</span>(prob)
solution$status</code></pre>
<pre><code>## [1] &quot;optimal&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">solution$<span class="kw">getValue</span>(x)</code></pre>
<pre><code>## [1] 0.3999978</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">solution$<span class="kw">getValue</span>(y)</code></pre>
<pre><code>## [1] 0.2000044</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## check that the solution satisfies the constraints
solution$<span class="kw">getValue</span>(x) &gt;=<span class="st"> </span><span class="dv">0</span></code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> *<span class="st"> </span>solution$<span class="kw">getValue</span>(x) +<span class="st"> </span>solution$<span class="kw">getValue</span>(y)</code></pre>
<pre><code>## [1] 1</code></pre>
</div>
<div id="least-squares" class="slide section level2">
<h1>Least squares</h1>
<p>We'll start off with the least squares problem and work up to more elaborate problems.</p>
<p>We are doing regression, so we have a response variable <span class="math">\(y \in \mathbb R^n\)</span> and predictor variables stored as the rows of a matrix <span class="math">\(X \in \mathbb R^{n \times p}\)</span>.</p>
<p>The least squares problem is <span class="math">\[
\text{minimize}_{\beta} \|y - X \beta\|_2^2
\]</span> or, written without matrix notation: <span class="math">\[
\text{minimize}_{\beta} \sum_{i=1}^n (y_i - \sum_{j=1}^pX_{ij} \beta_j)^2
\]</span></p>
<p>This is a very simple convex optimization problem, just an objective function to be minimized, no constraints on the parameters.</p>
</div>
<div id="example-dataset" class="slide section level2">
<h1>Example dataset</h1>
<p>The data set dating (in <code>lattice.RData</code>) contains paired observations giving the estimated ages of 19 coral samples in thousands of years using both carbon dating (the traditional method) and thorium dating (a modern and purportedly more accurate method.)</p>
<p>We want to know about the difference between these two methods.</p>
<p>We can set this up as a linear model:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="st">&quot;lattice.RData&quot;</span>)
dating_lm =<span class="st"> </span><span class="kw">lm</span>(thorium -<span class="st"> </span>carbon ~<span class="st"> </span>carbon, <span class="dt">data =</span> dating)
<span class="kw">round</span>(<span class="kw">coef</span>(dating_lm), <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>## (Intercept)      carbon 
##        0.14        0.16</code></pre>
</div>
<div class="slide section level2">

<div class="incremental">
<p>Let's try to solve the same problem with cvx.</p>
<p>First set up the data:</p>
<pre class="sourceCode r"><code class="sourceCode r">y =<span class="st"> </span>dating$thorium -<span class="st"> </span>dating$carbon
X =<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, dating$carbon)</code></pre>
<p>Define the optimization variables:</p>
<pre class="sourceCode r"><code class="sourceCode r">betahat =<span class="st"> </span><span class="kw">Variable</span>(<span class="dv">2</span>)</code></pre>
<p>Define the objective function:</p>
<pre class="sourceCode r"><code class="sourceCode r">objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>((y -<span class="st"> </span>X %*%<span class="st"> </span>betahat)^<span class="dv">2</span>))</code></pre>
<p>Solve the problem and get the fitted values:</p>
<pre class="sourceCode r"><code class="sourceCode r">problem =<span class="st"> </span><span class="kw">Problem</span>(objective)
result =<span class="st"> </span><span class="kw">solve</span>(problem)
<span class="kw">round</span>(result$<span class="kw">getValue</span>(betahat), <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##      [,1]
## [1,] 0.14
## [2,] 0.16</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">coef</span>(dating_lm), <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>## (Intercept)      carbon 
##        0.14        0.16</code></pre>
</div>
</div>
<div id="robust-regression" class="slide section level2">
<h1>Robust Regression</h1>
<p>If we look more carefully at our data, we see that there appear to be some outliers: most of the points follow one trend line, and the other two are far off.</p>
<p>This means that the least squares line doesn't do a good job of capturing either the bulk of the data or the outliers.</p>
<p>To deal with this situation, we sometimes use robust regression.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dating) +<span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> carbon, <span class="dt">y =</span> thorium -<span class="st"> </span>carbon)) +
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">intercept =</span> result$<span class="kw">getValue</span>(betahat)[<span class="dv">1</span>], <span class="dt">slope =</span> result$<span class="kw">getValue</span>(betahat)[<span class="dv">2</span>]))</code></pre>
<div class="figure">
<img src="lecture-20-fig/unnamed-chunk-11-1.png" />
</div>
</div>
<div class="slide section level2">

<p>Robust regression is a modification of least squares that is meant to deal with outliers.</p>
<p>The coefficients in the Huber version of robust regression are the solutions to the problem <span class="math">\[
\text{minimize}_\beta \quad \sum_{i=1}^n H(y_i - \sum_{j=1}^p X_{ij} \beta_j, M)
\]</span> where <span class="math">\(H\)</span> is the Huber loss function: <span class="math">\[
H(z, M) = \begin{cases}
z^2 &amp; z\le M \\
2M|z| - M^2 &amp; z &gt; M
\end{cases}
\]</span></p>
</div>
<div class="slide section level2">

<div class="incremental">
<p>Let's set up the problem in cvx.</p>
<p>Define the variables to optimize over:</p>
<pre class="sourceCode r"><code class="sourceCode r">betahat =<span class="st"> </span><span class="kw">Variable</span>(<span class="dv">2</span>)</code></pre>
<p>Define the objective function</p>
<pre class="sourceCode r"><code class="sourceCode r">objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>(<span class="kw">huber</span>(y -<span class="st"> </span>X %*%<span class="st"> </span>betahat, <span class="dt">M =</span> .<span class="dv">46</span>)))</code></pre>
<p>Solve the problem and get the fitted values for the regression coefficients:</p>
<pre class="sourceCode r"><code class="sourceCode r">problem =<span class="st"> </span><span class="kw">Problem</span>(objective)
result =<span class="st"> </span><span class="kw">solve</span>(problem)
result$<span class="kw">getValue</span>(betahat)</code></pre>
<pre><code>##            [,1]
## [1,] -0.4452392
## [2,]  0.2162504</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">fitted_betahat =<span class="st"> </span>result$<span class="kw">getValue</span>(betahat)</code></pre>
</div>
</div>
<div class="slide section level2">

<p>Compare the regression line from robust regression to the standard regression line:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dating) +<span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> carbon, <span class="dt">y =</span> thorium -<span class="st"> </span>carbon)) +
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">slope =</span> fitted_betahat[<span class="dv">2</span>], <span class="dt">intercept =</span> fitted_betahat[<span class="dv">1</span>]), <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) +
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">slope =</span> <span class="kw">coef</span>(dating_lm)[<span class="dv">2</span>], <span class="dt">intercept =</span> <span class="kw">coef</span>(dating_lm)[<span class="dv">1</span>]))</code></pre>
<div class="figure">
<img src="lecture-20-fig/unnamed-chunk-15-1.png" />
</div>
</div>
<div id="variable-selection" class="slide section level2">
<h1>Variable selection</h1>
<p>A popular way of doing variable selection in high-dimensional regression problems is with the lasso.</p>
<p>The Lasso is a simple modification of the least squares problem: <span class="math">\[
\text{minimize}_{\beta} \sum_{i=1}^n (y_i - \sum_{j=1}^p X_{ij} \beta_j) + \sum_{j=1}^p |\beta_j|
\]</span></p>
<p>The resulting coefficient vector tends to be &quot;sparse&quot;, with many of the coefficients being estimated as exactly 0.</p>
<p>This is helpful when you want a model for your response that only incorporates a subset of the predictors.</p>
</div>
<div id="diabetes-example" class="slide section level2">
<h1>Diabetes example</h1>
<p>Ten baseline variables: age, sex, bmi, average blood pressure, plus six blood serum measurements.</p>
<p>Want to use this to predict &quot;a quantitative measure of disease progression&quot; in 442 patients.</p>
<p>We don't necessarily think that all of the measured variables are important, and we want to get a model that uses only a subset of the variables but still gives us good predictive accuracy.</p>
<p>This is exactly what the lasso is for!</p>
</div>
<div class="slide section level2">

<p>First set up the data:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lars)
<span class="kw">data</span>(diabetes)
<span class="kw">head</span>(diabetes$x)</code></pre>
<pre><code>## [1]  0.038075906 -0.001882017  0.085298906 -0.089062939  0.005383060
## [6] -0.092695478</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">## re-doing this because diabetes has a funny class
X =<span class="st"> </span><span class="kw">matrix</span>(diabetes$x, <span class="dt">nrow =</span> <span class="kw">nrow</span>(diabetes$x), <span class="dt">ncol =</span> <span class="kw">ncol</span>(diabetes$x))
## changing X so each column has mean 0 and standard deviation 1
X =<span class="st"> </span><span class="kw">scale</span>(X)
Y =<span class="st"> </span>diabetes$y
n =<span class="st"> </span><span class="kw">nrow</span>(X)
p =<span class="st"> </span><span class="kw">ncol</span>(X)</code></pre>
</div>
<div class="slide section level2">

<div class="incremental">
<p>Let's set up the problem in cvx. Define the variables:</p>
<pre class="sourceCode r"><code class="sourceCode r">beta_lasso =<span class="st"> </span><span class="kw">Variable</span>(p)</code></pre>
<p>Define the objective function:</p>
<pre class="sourceCode r"><code class="sourceCode r">lambda =<span class="st"> </span><span class="dv">1</span>
objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>(n^(-<span class="dv">1</span>) *<span class="st"> </span>(Y -<span class="st"> </span>X %*%<span class="st"> </span>beta_lasso)^<span class="dv">2</span>) +<span class="st"> </span>lambda *<span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(beta_lasso)))</code></pre>
<p>Define the problem and solve:</p>
<pre class="sourceCode r"><code class="sourceCode r">problem =<span class="st"> </span><span class="kw">Problem</span>(objective)
result =<span class="st"> </span><span class="kw">solve</span>(problem)
<span class="kw">round</span>(result$<span class="kw">getValue</span>(beta_lasso), <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##         [,1]
##  [1,]  -0.03
##  [2,] -10.35
##  [3,]  25.01
##  [4,]  14.70
##  [5,]  -7.89
##  [6,]   0.00
##  [7,]  -8.38
##  [8,]   3.45
##  [9,]  24.98
## [10,]   2.95</code></pre>
</div>
</div>
<div class="slide section level2">

<p>Let's look at what happens to the coefficients with different values of <span class="math">\(\lambda\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">lambda_search =<span class="st"> </span><span class="dv">10</span>^(<span class="kw">seq</span>(-<span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">length.out =</span> <span class="dv">40</span>))
get_beta_hat_lasso =<span class="st"> </span>function(lambda) {
    objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>(n^(-<span class="dv">1</span>) *<span class="st"> </span>(Y -<span class="st"> </span>X %*%<span class="st"> </span>beta_lasso)^<span class="dv">2</span>) +<span class="st"> </span>lambda *<span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(beta_lasso)))
    problem =<span class="st"> </span><span class="kw">Problem</span>(objective)
    result =<span class="st"> </span><span class="kw">solve</span>(problem)
    result$<span class="kw">getValue</span>(beta_lasso)
}
beta_hats =<span class="st"> </span>plyr::<span class="kw">aaply</span>(lambda_search, <span class="dv">1</span>, get_beta_hat_lasso)
<span class="kw">colnames</span>(beta_hats) =<span class="st"> </span><span class="kw">colnames</span>(diabetes$x)
beta_hats =<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">lambda =</span> lambda_search, beta_hats)
<span class="kw">round</span>(beta_hats, <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##    lambda   age    sex   bmi   map     tc   ldl    hdl  tch   ltg  glu
## 1    0.01 -0.47 -11.41 24.76 15.44 -36.95 22.11   4.44 8.29 35.50 3.22
## 2    0.01 -0.47 -11.41 24.76 15.44 -36.81 22.00   4.36 8.26 35.45 3.22
## 3    0.02 -0.46 -11.40 24.76 15.43 -36.47 21.74   4.21 8.21 35.33 3.22
## 4    0.02 -0.46 -11.40 24.76 15.43 -36.15 21.50   4.06 8.15 35.21 3.22
## 5    0.03 -0.45 -11.40 24.77 15.42 -35.69 21.14   3.84 8.07 35.04 3.22
## 6    0.03 -0.44 -11.39 24.77 15.41 -35.22 20.78   3.61 7.98 34.88 3.22
## 7    0.04 -0.44 -11.38 24.77 15.40 -34.50 20.23   3.26 7.85 34.62 3.22
## 8    0.05 -0.43 -11.37 24.78 15.39 -33.63 19.56   2.85 7.70 34.31 3.21
## 9    0.07 -0.41 -11.36 24.78 15.38 -32.53 18.71   2.32 7.51 33.91 3.21
## 10   0.08 -0.39 -11.34 24.79 15.36 -31.14 17.64   1.66 7.27 33.41 3.21
## 11   0.11 -0.37 -11.32 24.81 15.33 -29.48 16.35   0.88 6.99 32.81 3.21
## 12   0.13 -0.34 -11.29 24.82 15.31 -27.74 14.98   0.11 6.75 32.17 3.20
## 13   0.17 -0.32 -11.24 24.84 15.29 -27.06 14.35  -0.03 6.84 31.89 3.19
## 14   0.22 -0.28 -11.16 24.89 15.25 -25.81 13.22  -0.31 6.96 31.37 3.16
## 15   0.27 -0.24 -11.09 24.92 15.20 -22.92 10.90  -1.52 6.64 30.30 3.15
## 16   0.35 -0.17 -11.00 24.97 15.13 -19.02  7.77  -3.15 6.20 28.85 3.12
## 17   0.44 -0.09 -10.89 25.03 15.05 -14.05  3.80  -5.25 5.62 27.01 3.10
## 18   0.55 -0.03 -10.75 25.08 14.96  -9.22  0.02  -7.33 4.96 25.24 3.07
## 19   0.70 -0.03 -10.61 25.06 14.87  -8.75  0.00  -7.70 4.43 25.15 3.02
## 20   0.89  0.00 -10.42 25.03 14.75  -8.16  0.00  -8.16 3.75 25.04 2.96
## 21   1.13  0.00 -10.19 24.99 14.61  -7.43  0.00  -8.72 2.90 24.91 2.88
## 22   1.43  0.00  -9.90 24.94 14.44  -6.51  0.00  -9.44 1.85 24.74 2.78
## 23   1.80  0.00  -9.55 24.89 14.21  -5.43  0.00 -10.23 0.65 24.54 2.67
## 24   2.29  0.00  -9.09 24.83 13.97  -4.55  0.00 -10.56 0.01 24.26 2.45
## 25   2.89  0.00  -8.56 24.76 13.69  -3.91  0.00 -10.39 0.00 23.87 2.20
## 26   3.67  0.00  -7.91 24.68 13.34  -3.11 -0.02 -10.20 0.00 23.36 1.92
## 27   4.64  0.00  -7.02 24.58 12.90  -2.05  0.00  -9.88 0.00 22.76 1.43
## 28   5.88  0.00  -5.93 24.45 12.33  -0.74  0.00  -9.53 0.00 21.98 0.89
## 29   7.44  0.00  -4.52 24.36 11.60   0.00  0.00  -8.76 0.00 21.49 0.36
## 30   9.43  0.00  -2.70 24.27 10.63   0.00  0.00  -7.44 0.00 21.32 0.03
## 31  11.94  0.00  -0.54 24.08  9.37   0.00  0.00  -5.82 0.00 20.98 0.00
## 32  15.12  0.00   0.00 23.55  8.29   0.00  0.00  -4.61 0.00 20.45 0.00
## 33  19.14  0.00   0.00 22.77  7.08   0.00  0.00  -3.39 0.00 19.74 0.00
## 34  24.24  0.00   0.00 21.77  5.57   0.00  0.00  -1.88 0.00 18.83 0.00
## 35  30.70  0.00   0.00 20.49  3.61   0.00  0.00  -0.07 0.00 17.64 0.00
## 36  38.88  0.00   0.00 18.32  1.27   0.00  0.00   0.00 0.00 15.47 0.00
## 37  49.24  0.00   0.00 15.08  0.00   0.00  0.00   0.00 0.00 12.22 0.00
## 38  62.36  0.00   0.00 10.54  0.00   0.00  0.00   0.00 0.00  7.68 0.00
## 39  78.97  0.00   0.00  4.76  0.00   0.00  0.00   0.00 0.00  1.95 0.00
## 40 100.00  0.00   0.00  0.00  0.00   0.00  0.00   0.00 0.00  0.00 0.00</code></pre>
</div>
<div class="slide section level2">

<p>Plot of the coefficients for different values of <span class="math">\(\lambda\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">beta_melted =<span class="st"> </span>reshape2::<span class="kw">melt</span>(<span class="kw">data.frame</span>(beta_hats), <span class="dt">id.vars =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">value.name =</span> <span class="st">&quot;coefficient&quot;</span>)
<span class="kw">ggplot</span>(beta_melted) +
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lambda, <span class="dt">y =</span> coefficient, <span class="dt">color =</span> variable, <span class="dt">lty =</span> variable)) +
<span class="st">    </span><span class="kw">scale_x_log10</span>()</code></pre>
<div class="figure">
<img src="lecture-20-fig/unnamed-chunk-21-1.png" />
</div>
</div>
<div id="both-together-now" class="slide section level2">
<h1>Both together now!</h1>
<p>What if we want to do both robust regression (we're worried about outliers or corrupted data) and variable selection?</p>
<p>We can use the Huber loss on the residuals and the lasso penalty on the coefficients: <span class="math">\[
\text{minimize}_{\beta} \sum_{i=1}^n H(y_i - \sum_{j=1}^pX_{ij}\beta_j, M)+ \sum_{j=1}^p |\beta_j|
\]</span></p>
<p>I don't know if there's an actual implementation of this in an R package, but it's easy to do with cvx.</p>
</div>
<div class="slide section level2">

<div class="incremental">
<p>Define the variable to be optimized over:</p>
<pre class="sourceCode r"><code class="sourceCode r">betahat =<span class="st"> </span><span class="kw">Variable</span>(p)</code></pre>
<p>Define the objective:</p>
<pre class="sourceCode r"><code class="sourceCode r">lambda =<span class="st"> </span><span class="dv">10</span>^(-<span class="dv">4</span>)
objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>(<span class="kw">huber</span>(Y -<span class="st"> </span>X %*%<span class="st"> </span>betahat)) +<span class="st"> </span>lambda *<span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(betahat)))</code></pre>
<p>Define the problem and solve it:</p>
<pre class="sourceCode r"><code class="sourceCode r">problem =<span class="st"> </span><span class="kw">Problem</span>(objective)
result =<span class="st"> </span><span class="kw">solve</span>(problem)
<span class="kw">round</span>(result$<span class="kw">getValue</span>(betahat), <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##       [,1]
##  [1,] 0.00
##  [2,] 0.00
##  [3,] 0.71
##  [4,] 0.00
##  [5,] 0.00
##  [6,] 0.00
##  [7,] 0.00
##  [8,] 0.00
##  [9,] 1.31
## [10,] 0.00</code></pre>
</div>
</div>
<div class="slide section level2">

<p>Searching over a grid of <span class="math">\(\lambda\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">lambda_search =<span class="st"> </span><span class="dv">10</span>^(<span class="kw">seq</span>(-<span class="dv">6</span>, -<span class="dv">3</span>, <span class="dt">length.out =</span> <span class="dv">40</span>))
get_beta_hat_lasso =<span class="st"> </span>function(lambda) {
    objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>(<span class="kw">huber</span>(Y -<span class="st"> </span>X %*%<span class="st"> </span>beta_lasso)) +<span class="st"> </span>lambda *<span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(beta_lasso)))
    problem =<span class="st"> </span><span class="kw">Problem</span>(objective)
    result =<span class="st"> </span><span class="kw">solve</span>(problem)
    result$<span class="kw">getValue</span>(beta_lasso)
}
beta_hats =<span class="st"> </span>plyr::<span class="kw">aaply</span>(lambda_search, <span class="dv">1</span>, get_beta_hat_lasso)
<span class="kw">colnames</span>(beta_hats) =<span class="st"> </span><span class="kw">colnames</span>(diabetes$x)
beta_hats =<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">lambda =</span> lambda_search, beta_hats)
<span class="kw">round</span>(beta_hats, <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre>
<pre><code>##    lambda  age   sex   bmi   map    tc   ldl   hdl   tch   ltg  glu
## 1       0 3.78 -4.26 19.91 10.54 -1.45 -7.03 -2.60 11.24 17.53 4.39
## 2       0 3.78 -4.25 19.92 10.51 -0.86 -7.41 -2.96 10.97 17.34 4.42
## 3       0 3.79 -4.26 19.91 10.54 -1.46 -7.14 -2.49 11.41 17.53 4.39
## 4       0 3.76 -4.21 19.91 10.48 -1.15 -7.24 -2.71 11.15 17.45 4.39
## 5       0 3.73 -4.15 19.87 10.48 -1.18 -7.08 -2.74 11.01 17.49 4.37
## 6       0 3.71 -4.11 19.87 10.46 -0.99 -7.16 -2.84 10.90 17.44 4.36
## 7       0 3.71 -4.10 19.87 10.45 -0.60 -7.43 -3.03 10.80 17.31 4.36
## 8       0 3.69 -4.05 19.86 10.43 -0.32 -7.57 -3.17 10.67 17.22 4.35
## 9       0 3.66 -4.00 19.83 10.41 -0.99 -6.91 -2.93 10.59 17.50 4.34
## 10      0 3.65 -3.94 19.82 10.37  0.07 -7.59 -3.49 10.23 17.14 4.34
## 11      0 3.58 -3.80 19.77 10.30 -0.42 -6.85 -3.44  9.82 17.41 4.31
## 12      0 3.51 -3.66 19.73 10.23 -0.92 -6.12 -3.37  9.43 17.68 4.27
## 13      0 3.58 -3.79 19.77 10.31  0.01 -7.28 -3.50  9.95 17.20 4.31
## 14      0 3.54 -3.68 19.65 10.20 -1.23 -5.68 -3.47  9.15 17.79 4.34
## 15      0 3.39 -3.37 19.62 10.06 -1.20 -5.10 -3.69  8.36 17.96 4.24
## 16      0 3.20 -3.02 19.56  9.91 -0.42 -5.02 -4.22  7.43 17.84 4.15
## 17      0 2.99 -2.63 19.46  9.76 -0.01 -4.59 -4.59  6.47 17.86 4.05
## 18      0 1.90 -0.49 19.07  8.82  0.00 -0.60 -5.79  1.39 18.86 3.55
## 19      0 1.70 -0.01 18.95  8.58  0.00 -0.14 -5.83  0.73 18.92 3.50
## 20      0 1.85 -1.19 18.71  8.76  0.00 -0.16 -6.26  0.87 18.68 3.64
## 21      0 1.17  0.05 18.56  8.11  0.00  0.00 -5.33  0.60 18.67 3.28
## 22      0 0.00  0.00 17.52  6.76  0.00  0.00 -3.28  0.91 17.97 2.19
## 23      0 0.00  0.00 10.22  0.00  0.00  0.00  0.00  0.00 11.56 0.00
## 24      0 0.34 -0.01 17.88  7.52  0.00  0.00 -4.22  1.06 18.13 2.87
## 25      0 0.00  0.00  0.14  0.00  0.00  0.00  0.00  0.00  0.78 0.00
## 26      0 0.00  0.00  0.08  0.00  0.00  0.00  0.00  0.00  0.93 0.00
## 27      0 0.00  0.00  0.71  0.00  0.00  0.00  0.00  0.00  1.31 0.00
## 28      0 0.00  0.00  0.20  0.00  0.00  0.00  0.00  0.00  0.07 0.00
## 29      0 0.00  0.00 15.24  4.71  0.00  0.00 -0.48  2.37 15.73 1.07
## 30      0 0.00  0.00  0.37  0.00  0.00  0.00  0.00  0.00  0.11 0.00
## 31      0 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.24 0.00
## 32      0 0.00  0.00  0.02  0.00  0.00  0.00  0.00  0.00  0.02 0.00
## 33      0 0.00  0.00  0.01  0.00  0.00  0.00  0.00  0.00  0.83 0.00
## 34      0 0.00  0.00  0.01  0.00  0.00  0.00  0.00  0.00  0.41 0.00
## 35      0 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.01 0.00
## 36      0 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.01 0.00
## 37      0 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00 0.00
## 38      0 0.00  0.00  0.06  0.00  0.00  0.00  0.00  0.00  0.03 0.00
## 39      0 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00 0.00
## 40      0 0.00  0.00  0.04  0.00  0.00  0.00  0.00  0.01  0.00 0.00</code></pre>
</div>
<div class="slide section level2">

<p>Plot of the coefficients for different values of <span class="math">\(\lambda\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">beta_melted =<span class="st"> </span>reshape2::<span class="kw">melt</span>(<span class="kw">data.frame</span>(beta_hats), <span class="dt">id.vars =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">value.name =</span> <span class="st">&quot;coefficient&quot;</span>)
<span class="kw">ggplot</span>(beta_melted) +
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lambda, <span class="dt">y =</span> coefficient, <span class="dt">color =</span> variable, <span class="dt">lty =</span> variable)) +
<span class="st">    </span><span class="kw">scale_x_log10</span>()</code></pre>
<div class="figure">
<img src="lecture-20-fig/unnamed-chunk-26-1.png" />
</div>
</div>
<div id="summing-up" class="slide section level2">
<h1>Summing up</h1>
<ul>
<li><p>Many statistical problems and variations can be expressed as convex optimization problems.</p></li>
<li><p>These are cheap and easy to fit, and you don't need to rely on your exact problem being implemented by someone else.</p></li>
<li><p>Cvx behind the scenes is using some of the methods that we've been discussing the past couple of weeks.</p></li>
</ul>
</div>
</body>
</html>
