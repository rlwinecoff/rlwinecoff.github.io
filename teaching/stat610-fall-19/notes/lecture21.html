<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>lecture21</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" type="text/css" media="screen, projection, print"
    href="https://www.w3.org/Talks/Tools/Slidy2/styles/slidy.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <script src="https://www.w3.org/Talks/Tools/Slidy2/scripts/slidy.js"
    charset="utf-8" type="text/javascript"></script>
</head>
<body>
<div id="applications-and-cvx" class="slide section level2">
<h1>Applications and cvx</h1>
<p>Agenda today</p>
<ul>
<li><p>cvx, package for fitting convex problems in general</p></li>
<li><p>Optimization applications in statistics</p></li>
</ul>
</div>
<div id="convex-optimization-problem" class="slide section level2">
<h1>Convex optimization problem</h1>
<p>In a convex optimization problem, we minimize a convex function over a convex set.</p>
<div class="incremental">
<p>Standard form for an optimization problem is:</p>
<p><span class="math display">\[
\begin{align*}
\text{minimize} \quad &amp;f_0(x) \\
\text{subject to}\quad  &amp;f_i(x) \le 0, \quad i = 1,\ldots, m\\
&amp;a_j^T x = b_j, \quad j = 1,\ldots, n
\end{align*}
\]</span></p>
<ul>
<li><p><span class="math inline">\(x \in \mathbb R^n\)</span> is the optimization variable</p></li>
<li><p><span class="math inline">\(f_0: \mathbb R^n \to \mathbb R\)</span> is the objective function</p></li>
<li><p><span class="math inline">\(f_i : \mathbb R^n \to \mathbb R\)</span> are the inequality constraint functions</p></li>
<li><p><span class="math inline">\(a_j^T x = b_j\)</span> are the equality constraints</p></li>
</ul>
</div>
</div>
<div id="regression" class="slide section level2">
<h1>Regression</h1>
<p>Standard least squares problem is convex: <span class="math display">\[
\text{minimize} \|y - X \beta\|_2^2
\]</span></p>
</div>
<div id="regularized-regression" class="slide section level2">
<h1>Regularized regression</h1>
<p>Any “regularization” with a convex function <span class="math inline">\(P\)</span> will still be convex:</p>
<p><span class="math display">\[
\text{minimize} \|y - X \beta\|_2^2 + P(\beta)
\]</span></p>
</div>
<div id="covariance-estimation" class="slide section level2">
<h1>Covariance estimation</h1>
<p>Let <span class="math inline">\(S\)</span> denote the sample covariance and <span class="math inline">\(\Theta\)</span> be the inverse covariance matrix.</p>
<p>Up to constant factors, the log-likelihood of the data given a Gaussian distribution is</p>
<p><span class="math display">\[
\log \det \Theta - \text{tr}(S \Theta)
\]</span></p>
<p>Covariance estimation would be by maximizing the log likelihood or minimizing the negative log likelihood.</p>
<div class="incremental">
<ul>
<li><p><span class="math inline">\(\log \det\)</span> is concave, <span class="math inline">\(\text{tr}(S \Theta)\)</span> is linear</p></li>
<li><p>Restriction of <span class="math inline">\(\Theta\)</span> to be positive definite is a restriction to a convex set</p></li>
<li><p>Convex problem; remains convex if we add convex penalties to <span class="math inline">\(\Theta\)</span></p></li>
</ul>
</div>
</div>
<div id="summing-up" class="slide section level2">
<h1>Summing up</h1>
<p>If you can show an optimization problem is convex, you’re very likely able to solve it efficiently</p>
<p>Many statistical estimation problems are naturally convex</p>
<p>You have a couple of options for checking convexity:</p>
<ul>
<li><p>Check the definition</p></li>
<li><p>Check first-order conditions (not usually as useful)</p></li>
<li><p>Check second-order conditions (good option if the function is differentiable)</p></li>
<li><p>Check restriction to a line</p></li>
<li><p>Check whether the function can be re-expressed as a combination of convex functions and convexity-preserving operations</p></li>
</ul>
</div>
<div id="defining-an-optimization-problem-in-cvx" class="slide section level2">
<h1>Defining an optimization problem in cvx</h1>
<p>Remember how we defined a convex optimization problem:</p>
<p><span class="math display">\[
\begin{align*}
\text{minimize} \quad &amp;f_0(x) \\
\text{subject to}\quad &amp;f_i(x) \le 0, \quad i = 1,\ldots, m\\
&amp;a_j^T x = b_j, \quad j = 1,\ldots, n
\end{align*}
\]</span></p>
<p>Components:</p>
<ul>
<li><p>Variables to minimize over (<span class="math inline">\(x\)</span> in the formulation above, can be multi-dimensional)</p></li>
<li><p>Objective function (<span class="math inline">\(f_0\)</span> above, what we want to minimize)</p></li>
<li><p>Constraints on the variables</p></li>
</ul>
<p>In the cvx package, we define these three components, create a problem out of them, and the solver will do the rest.</p>
</div>
<div id="example" class="slide section level2">
<h1>Example</h1>
<p>For example, suppose our problem is: <span class="math display">\[
\begin{align*}
\text{minimize}_{x, y} \quad &amp;x^2 + y^2 \\
\text{subject to} \quad &amp;x \ge 0\\
&amp; 2x + y = 1
\end{align*}
\]</span></p>
<p>How do we set this up in cvx/R?</p>
</div>
<div class="slide section level2">

<p>Define the variables to be minimized over:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">library</span>(CVXR)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;CVXR&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     power</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Variables minimized over</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>x =<span class="st"> </span><span class="kw">Variable</span>(<span class="dv">1</span>)</span>
<span id="cb4-3"><a href="#cb4-3"></a>y =<span class="st"> </span><span class="kw">Variable</span>(<span class="dv">1</span>)</span>
<span id="cb4-4"><a href="#cb4-4"></a>x</span></code></pre></div>
<pre><code>## Variable(1, 1)</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">class</span>(x)</span></code></pre></div>
<pre><code>## [1] &quot;Variable&quot;
## attr(,&quot;package&quot;)
## [1] &quot;CVXR&quot;</code></pre>
</div>
<div class="slide section level2">

<p>Define the objective function:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># The function we want to minimize</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>objective =<span class="st"> </span><span class="kw">Minimize</span>(x<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>y<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb8-3"><a href="#cb8-3"></a>objective</span></code></pre></div>
<pre><code>## An object of class &quot;Minimize&quot;
## Slot &quot;expr&quot;:
## AddExpression(c(&quot;Expression(CONVEX, POSITIVE, 1)&quot;, &quot;Expression(CONVEX, POSITIVE, 1)&quot;), c(&quot;Expression(CONVEX, POSITIVE, 1)&quot;, &quot;Expression(CONVEX, POSITIVE, 1)&quot;))</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">class</span>(objective)</span></code></pre></div>
<pre><code>## [1] &quot;Minimize&quot;
## attr(,&quot;package&quot;)
## [1] &quot;CVXR&quot;</code></pre>
</div>
<div class="slide section level2">

<p>Define the constraints:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a><span class="co">## The constraints</span></span>
<span id="cb12-2"><a href="#cb12-2"></a>constraints =<span class="st"> </span><span class="kw">list</span>(x <span class="op">&gt;=</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>x <span class="op">+</span><span class="st"> </span>y <span class="op">==</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb12-3"><a href="#cb12-3"></a>constraints</span></code></pre></div>
<pre><code>## [[1]]
## LeqConstraint(Constant(CONSTANT, ZERO, (1,1)), Variable(1, 1))
## [[2]]
## EqConstraint(Expression(AFFINE, UNKNOWN, 1), Expression(AFFINE, UNKNOWN, 1), Constant(CONSTANT, POSITIVE, (1,1)))</code></pre>
</div>
<div class="slide section level2">

<p>The optimization problem is then composed of the objective and the constraints:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a><span class="co">## Problem definition</span></span>
<span id="cb14-2"><a href="#cb14-2"></a>prob &lt;-<span class="st"> </span><span class="kw">Problem</span>(objective, constraints)</span></code></pre></div>
</div>
<div class="slide section level2">

<p>To perform the optimization we use <code>solve(problem)</code></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="co"># Problem solution</span></span>
<span id="cb15-2"><a href="#cb15-2"></a>solution =<span class="st"> </span><span class="kw">solve</span>(prob)</span>
<span id="cb15-3"><a href="#cb15-3"></a>solution<span class="op">$</span>status</span></code></pre></div>
<pre><code>## [1] &quot;optimal&quot;</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a>solution<span class="op">$</span><span class="kw">getValue</span>(x)</span></code></pre></div>
<pre><code>## [1] 0.3999978</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a>solution<span class="op">$</span><span class="kw">getValue</span>(y)</span></code></pre></div>
<pre><code>## [1] 0.2000044</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a><span class="co">## check that the solution satisfies the constraints</span></span>
<span id="cb21-2"><a href="#cb21-2"></a>solution<span class="op">$</span><span class="kw">getValue</span>(x) <span class="op">&gt;=</span><span class="st"> </span><span class="dv">0</span></span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>solution<span class="op">$</span><span class="kw">getValue</span>(x) <span class="op">+</span><span class="st"> </span>solution<span class="op">$</span><span class="kw">getValue</span>(y)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
</div>
<div id="least-squares" class="slide section level2">
<h1>Least squares</h1>
<p>We’ll start off with the least squares problem and work up to more elaborate problems.</p>
<p>We are doing regression, so we have a response variable <span class="math inline">\(y \in \mathbb R^n\)</span> and predictor variables stored as the rows of a matrix <span class="math inline">\(X \in \mathbb R^{n \times p}\)</span>.</p>
<p>The least squares problem is <span class="math display">\[
\text{minimize}_{\beta} \|y - X \beta\|_2^2
\]</span> or, written without matrix notation: <span class="math display">\[
\text{minimize}_{\beta} \sum_{i=1}^n (y_i - \sum_{j=1}^pX_{ij} \beta_j)^2
\]</span></p>
<p>This is a very simple convex optimization problem, just an objective function to be minimized, no constraints on the parameters.</p>
</div>
<div id="example-dataset" class="slide section level2">
<h1>Example dataset</h1>
<p>The data set dating (in <code>lattice.RData</code>) contains paired observations giving the estimated ages of 19 coral samples in thousands of years using both carbon dating (the traditional method) and thorium dating (a modern and purportedly more accurate method.)</p>
<p>We want to know about the difference between these two methods.</p>
<p>We can set this up as a linear model:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="kw">load</span>(<span class="st">&quot;lattice.RData&quot;</span>)</span>
<span id="cb25-2"><a href="#cb25-2"></a>dating_lm =<span class="st"> </span><span class="kw">lm</span>(thorium <span class="op">-</span><span class="st"> </span>carbon <span class="op">~</span><span class="st"> </span>carbon, <span class="dt">data =</span> dating)</span>
<span id="cb25-3"><a href="#cb25-3"></a><span class="kw">round</span>(<span class="kw">coef</span>(dating_lm), <span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## (Intercept)      carbon 
##        0.14        0.16</code></pre>
</div>
<div class="slide section level2">

<div class="incremental">
<p>Let’s try to solve the same problem with cvx.</p>
<p>First set up the data:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a>y =<span class="st"> </span>dating<span class="op">$</span>thorium <span class="op">-</span><span class="st"> </span>dating<span class="op">$</span>carbon</span>
<span id="cb27-2"><a href="#cb27-2"></a>X =<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, dating<span class="op">$</span>carbon)</span></code></pre></div>
<p>Define the optimization variables:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a>betahat =<span class="st"> </span><span class="kw">Variable</span>(<span class="dv">2</span>)</span></code></pre></div>
<p>Define the objective function:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a>objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>((y <span class="op">-</span><span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>betahat)<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<p>Solve the problem and get the fitted values:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1"></a>problem =<span class="st"> </span><span class="kw">Problem</span>(objective)</span>
<span id="cb30-2"><a href="#cb30-2"></a>result =<span class="st"> </span><span class="kw">solve</span>(problem)</span>
<span id="cb30-3"><a href="#cb30-3"></a><span class="kw">round</span>(result<span class="op">$</span><span class="kw">getValue</span>(betahat), <span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##      [,1]
## [1,] 0.14
## [2,] 0.16</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1"></a><span class="kw">round</span>(<span class="kw">coef</span>(dating_lm), <span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## (Intercept)      carbon 
##        0.14        0.16</code></pre>
</div>
</div>
<div id="robust-regression" class="slide section level2">
<h1>Robust Regression</h1>
<p>If we look more carefully at our data, we see that there appear to be some outliers: most of the points follow one trend line, and the other two are far off.</p>
<p>This means that the least squares line doesn’t do a good job of capturing either the bulk of the data or the outliers.</p>
<p>To deal with this situation, we sometimes use robust regression.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1"></a><span class="kw">ggplot</span>(dating) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> carbon, <span class="dt">y =</span> thorium <span class="op">-</span><span class="st"> </span>carbon)) <span class="op">+</span></span>
<span id="cb34-2"><a href="#cb34-2"></a><span class="st">    </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">intercept =</span> result<span class="op">$</span><span class="kw">getValue</span>(betahat)[<span class="dv">1</span>], <span class="dt">slope =</span> result<span class="op">$</span><span class="kw">getValue</span>(betahat)[<span class="dv">2</span>]))</span></code></pre></div>
<p><img src="lecture-21-fig/unnamed-chunk-11-1.png" /></p>
</div>
<div class="slide section level2">

<p>Robust regression is a modification of least squares that is meant to deal with outliers.</p>
<p>The coefficients in the Huber version of robust regression are the solutions to the problem <span class="math display">\[
\text{minimize}_\beta \quad \sum_{i=1}^n H(y_i - \sum_{j=1}^p X_{ij} \beta_j, M)
\]</span> where <span class="math inline">\(H\)</span> is the Huber loss function: <span class="math display">\[
H(z, M) = \begin{cases}
z^2 &amp; z\le M \\
2M|z| - M^2 &amp; z &gt; M
\end{cases}
\]</span></p>
</div>
<div class="slide section level2">

<div class="incremental">
<p>Let’s set up the problem in cvx.</p>
<p>Define the variables to optimize over:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1"></a>betahat =<span class="st"> </span><span class="kw">Variable</span>(<span class="dv">2</span>)</span></code></pre></div>
<p>Define the objective function</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1"></a>objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>(<span class="kw">huber</span>(y <span class="op">-</span><span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>betahat, <span class="dt">M =</span> <span class="fl">.46</span>)))</span></code></pre></div>
<p>Solve the problem and get the fitted values for the regression coefficients:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1"></a>problem =<span class="st"> </span><span class="kw">Problem</span>(objective)</span>
<span id="cb37-2"><a href="#cb37-2"></a>result =<span class="st"> </span><span class="kw">solve</span>(problem)</span>
<span id="cb37-3"><a href="#cb37-3"></a>result<span class="op">$</span><span class="kw">getValue</span>(betahat)</span></code></pre></div>
<pre><code>##            [,1]
## [1,] -0.4452392
## [2,]  0.2162504</code></pre>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1"></a>fitted_betahat =<span class="st"> </span>result<span class="op">$</span><span class="kw">getValue</span>(betahat)</span></code></pre></div>
</div>
</div>
<div class="slide section level2">

<p>Compare the regression line from robust regression to the standard regression line:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1"></a><span class="kw">ggplot</span>(dating) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> carbon, <span class="dt">y =</span> thorium <span class="op">-</span><span class="st"> </span>carbon)) <span class="op">+</span></span>
<span id="cb40-2"><a href="#cb40-2"></a><span class="st">    </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">slope =</span> fitted_betahat[<span class="dv">2</span>], <span class="dt">intercept =</span> fitted_betahat[<span class="dv">1</span>]), <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span></span>
<span id="cb40-3"><a href="#cb40-3"></a><span class="st">    </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">slope =</span> <span class="kw">coef</span>(dating_lm)[<span class="dv">2</span>], <span class="dt">intercept =</span> <span class="kw">coef</span>(dating_lm)[<span class="dv">1</span>]))</span></code></pre></div>
<p><img src="lecture-21-fig/unnamed-chunk-15-1.png" /></p>
</div>
<div id="variable-selection" class="slide section level2">
<h1>Variable selection</h1>
<p>A popular way of doing variable selection in high-dimensional regression problems is with the lasso.</p>
<p>The Lasso is a simple modification of the least squares problem: <span class="math display">\[
\text{minimize}_{\beta} \sum_{i=1}^n (y_i - \sum_{j=1}^p X_{ij} \beta_j)^2 + \lambda\sum_{j=1}^p |\beta_j|
\]</span></p>
<p>The resulting coefficient vector tends to be “sparse”, with many of the coefficients being estimated as exactly 0.</p>
<p>This is helpful when you want a model for your response that only incorporates a subset of the predictors.</p>
</div>
<div id="diabetes-example" class="slide section level2">
<h1>Diabetes example</h1>
<p>Ten baseline variables: age, sex, bmi, average blood pressure, plus six blood serum measurements.</p>
<p>Want to use this to predict “a quantitative measure of disease progression” in 442 patients.</p>
<p>We don’t necessarily think that all of the measured variables are important, and we want to get a model that uses only a subset of the variables but still gives us good predictive accuracy.</p>
<p>This is exactly what the lasso is for!</p>
</div>
<div class="slide section level2">

<p>First set up the data:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1"></a><span class="kw">library</span>(lars)</span></code></pre></div>
<pre><code>## Loaded lars 1.2</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1"></a><span class="kw">data</span>(diabetes)</span>
<span id="cb43-2"><a href="#cb43-2"></a><span class="kw">head</span>(diabetes<span class="op">$</span>x)</span></code></pre></div>
<pre><code>## [1]  0.038075906 -0.001882017  0.085298906 -0.089062939  0.005383060
## [6] -0.092695478</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a><span class="co">## re-doing this because diabetes has a funny class</span></span>
<span id="cb45-2"><a href="#cb45-2"></a>X =<span class="st"> </span><span class="kw">matrix</span>(diabetes<span class="op">$</span>x, <span class="dt">nrow =</span> <span class="kw">nrow</span>(diabetes<span class="op">$</span>x), <span class="dt">ncol =</span> <span class="kw">ncol</span>(diabetes<span class="op">$</span>x))</span>
<span id="cb45-3"><a href="#cb45-3"></a><span class="co">## changing X so each column has mean 0 and standard deviation 1</span></span>
<span id="cb45-4"><a href="#cb45-4"></a>X =<span class="st"> </span><span class="kw">scale</span>(X)</span>
<span id="cb45-5"><a href="#cb45-5"></a>Y =<span class="st"> </span>diabetes<span class="op">$</span>y</span>
<span id="cb45-6"><a href="#cb45-6"></a>n =<span class="st"> </span><span class="kw">nrow</span>(X)</span>
<span id="cb45-7"><a href="#cb45-7"></a>p =<span class="st"> </span><span class="kw">ncol</span>(X)</span></code></pre></div>
</div>
<div class="slide section level2">

<div class="incremental">
<p>Let’s set up the problem in cvx. Define the variables:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1"></a>beta_lasso =<span class="st"> </span><span class="kw">Variable</span>(p)</span></code></pre></div>
<p>Define the objective function:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1"></a>lambda =<span class="st"> </span><span class="dv">1</span></span>
<span id="cb47-2"><a href="#cb47-2"></a>objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>(n<span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(Y <span class="op">-</span><span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>beta_lasso)<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>lambda <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(beta_lasso)))</span></code></pre></div>
<p>Define the problem and solve:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1"></a>problem =<span class="st"> </span><span class="kw">Problem</span>(objective)</span>
<span id="cb48-2"><a href="#cb48-2"></a>result =<span class="st"> </span><span class="kw">solve</span>(problem)</span>
<span id="cb48-3"><a href="#cb48-3"></a><span class="kw">round</span>(result<span class="op">$</span><span class="kw">getValue</span>(beta_lasso), <span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##         [,1]
##  [1,]  -0.03
##  [2,] -10.35
##  [3,]  25.01
##  [4,]  14.70
##  [5,]  -7.89
##  [6,]   0.00
##  [7,]  -8.38
##  [8,]   3.45
##  [9,]  24.98
## [10,]   2.95</code></pre>
</div>
</div>
<div class="slide section level2">

<p>Let’s look at what happens to the coefficients with different values of <span class="math inline">\(\lambda\)</span>:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1"></a>lambda_search =<span class="st"> </span><span class="dv">10</span><span class="op">^</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">length.out =</span> <span class="dv">40</span>))</span>
<span id="cb50-2"><a href="#cb50-2"></a>get_beta_hat_lasso =<span class="st"> </span><span class="cf">function</span>(lambda) {</span>
<span id="cb50-3"><a href="#cb50-3"></a>    objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>(n<span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(Y <span class="op">-</span><span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>beta_lasso)<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>lambda <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(beta_lasso)))</span>
<span id="cb50-4"><a href="#cb50-4"></a>    problem =<span class="st"> </span><span class="kw">Problem</span>(objective)</span>
<span id="cb50-5"><a href="#cb50-5"></a>    result =<span class="st"> </span><span class="kw">solve</span>(problem)</span>
<span id="cb50-6"><a href="#cb50-6"></a>    result<span class="op">$</span><span class="kw">getValue</span>(beta_lasso)</span>
<span id="cb50-7"><a href="#cb50-7"></a>}</span>
<span id="cb50-8"><a href="#cb50-8"></a>beta_hats =<span class="st"> </span>plyr<span class="op">::</span><span class="kw">aaply</span>(lambda_search, <span class="dv">1</span>, get_beta_hat_lasso)</span>
<span id="cb50-9"><a href="#cb50-9"></a><span class="kw">colnames</span>(beta_hats) =<span class="st"> </span><span class="kw">colnames</span>(diabetes<span class="op">$</span>x)</span>
<span id="cb50-10"><a href="#cb50-10"></a>beta_hats =<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">lambda =</span> lambda_search, beta_hats)</span>
<span id="cb50-11"><a href="#cb50-11"></a><span class="kw">round</span>(beta_hats, <span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##    lambda   age    sex   bmi   map     tc   ldl    hdl  tch   ltg  glu
## 1    0.01 -0.47 -11.41 24.76 15.44 -36.95 22.11   4.44 8.29 35.50 3.22
## 2    0.01 -0.47 -11.41 24.76 15.44 -36.81 22.00   4.36 8.26 35.45 3.22
## 3    0.02 -0.46 -11.40 24.76 15.43 -36.47 21.74   4.21 8.21 35.33 3.22
## 4    0.02 -0.46 -11.40 24.76 15.43 -36.15 21.50   4.06 8.15 35.21 3.22
## 5    0.03 -0.45 -11.40 24.77 15.42 -35.69 21.14   3.84 8.07 35.04 3.22
## 6    0.03 -0.44 -11.39 24.77 15.41 -35.22 20.78   3.61 7.98 34.88 3.22
## 7    0.04 -0.44 -11.38 24.77 15.40 -34.50 20.23   3.26 7.85 34.62 3.22
## 8    0.05 -0.43 -11.37 24.78 15.39 -33.63 19.56   2.85 7.70 34.31 3.21
## 9    0.07 -0.41 -11.36 24.78 15.38 -32.53 18.71   2.32 7.51 33.91 3.21
## 10   0.08 -0.39 -11.34 24.79 15.36 -31.14 17.64   1.66 7.27 33.41 3.21
## 11   0.11 -0.37 -11.32 24.81 15.33 -29.48 16.35   0.88 6.99 32.81 3.21
## 12   0.13 -0.34 -11.29 24.82 15.31 -27.74 14.98   0.11 6.75 32.17 3.20
## 13   0.17 -0.32 -11.24 24.84 15.29 -27.06 14.35  -0.03 6.84 31.89 3.19
## 14   0.22 -0.28 -11.16 24.89 15.25 -25.81 13.22  -0.31 6.96 31.37 3.16
## 15   0.27 -0.24 -11.09 24.92 15.20 -22.92 10.90  -1.52 6.64 30.30 3.15
## 16   0.35 -0.17 -11.00 24.97 15.13 -19.02  7.77  -3.15 6.20 28.85 3.12
## 17   0.44 -0.09 -10.89 25.03 15.05 -14.05  3.80  -5.25 5.62 27.01 3.10
## 18   0.55 -0.03 -10.75 25.08 14.96  -9.22  0.02  -7.33 4.96 25.24 3.07
## 19   0.70 -0.03 -10.61 25.06 14.87  -8.75  0.00  -7.70 4.43 25.15 3.02
## 20   0.89  0.00 -10.42 25.03 14.75  -8.16  0.00  -8.16 3.75 25.04 2.96
## 21   1.13  0.00 -10.19 24.99 14.61  -7.43  0.00  -8.72 2.90 24.91 2.88
## 22   1.43  0.00  -9.90 24.94 14.44  -6.51  0.00  -9.44 1.85 24.74 2.78
## 23   1.80  0.00  -9.55 24.89 14.21  -5.43  0.00 -10.23 0.65 24.54 2.67
## 24   2.29  0.00  -9.09 24.83 13.97  -4.55  0.00 -10.56 0.01 24.26 2.45
## 25   2.89  0.00  -8.56 24.76 13.69  -3.91  0.00 -10.39 0.00 23.87 2.20
## 26   3.67  0.00  -7.91 24.68 13.34  -3.11 -0.02 -10.20 0.00 23.36 1.92
## 27   4.64  0.00  -7.02 24.58 12.90  -2.05  0.00  -9.88 0.00 22.76 1.43
## 28   5.88  0.00  -5.93 24.45 12.33  -0.74  0.00  -9.53 0.00 21.98 0.89
## 29   7.44  0.00  -4.52 24.36 11.60   0.00  0.00  -8.76 0.00 21.49 0.36
## 30   9.43  0.00  -2.70 24.27 10.63   0.00  0.00  -7.44 0.00 21.32 0.03
## 31  11.94  0.00  -0.54 24.08  9.37   0.00  0.00  -5.82 0.00 20.98 0.00
## 32  15.12  0.00   0.00 23.55  8.29   0.00  0.00  -4.61 0.00 20.45 0.00
## 33  19.14  0.00   0.00 22.77  7.08   0.00  0.00  -3.39 0.00 19.74 0.00
## 34  24.24  0.00   0.00 21.77  5.57   0.00  0.00  -1.88 0.00 18.83 0.00
## 35  30.70  0.00   0.00 20.49  3.61   0.00  0.00  -0.07 0.00 17.64 0.00
## 36  38.88  0.00   0.00 18.32  1.27   0.00  0.00   0.00 0.00 15.47 0.00
## 37  49.24  0.00   0.00 15.08  0.00   0.00  0.00   0.00 0.00 12.22 0.00
## 38  62.36  0.00   0.00 10.54  0.00   0.00  0.00   0.00 0.00  7.68 0.00
## 39  78.97  0.00   0.00  4.76  0.00   0.00  0.00   0.00 0.00  1.95 0.00
## 40 100.00  0.00   0.00  0.00  0.00   0.00  0.00   0.00 0.00  0.00 0.00</code></pre>
</div>
<div class="slide section level2">

<p>Plot of the coefficients for different values of <span class="math inline">\(\lambda\)</span>:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1"></a>beta_melted =<span class="st"> </span>reshape2<span class="op">::</span><span class="kw">melt</span>(<span class="kw">data.frame</span>(beta_hats), <span class="dt">id.vars =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">value.name =</span> <span class="st">&quot;coefficient&quot;</span>)</span>
<span id="cb52-2"><a href="#cb52-2"></a><span class="kw">ggplot</span>(beta_melted) <span class="op">+</span></span>
<span id="cb52-3"><a href="#cb52-3"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lambda, <span class="dt">y =</span> coefficient, <span class="dt">color =</span> variable, <span class="dt">lty =</span> variable)) <span class="op">+</span></span>
<span id="cb52-4"><a href="#cb52-4"></a><span class="st">    </span><span class="kw">scale_x_log10</span>()</span></code></pre></div>
<p><img src="lecture-21-fig/unnamed-chunk-21-1.png" /></p>
</div>
<div id="both-together-now" class="slide section level2">
<h1>Both together now!</h1>
<p>What if we want to do both robust regression (we’re worried about outliers or corrupted data) and variable selection?</p>
<p>We can use the Huber loss on the residuals and the lasso penalty on the coefficients: <span class="math display">\[
\text{minimize}_{\beta} \sum_{i=1}^n H(y_i - \sum_{j=1}^pX_{ij}\beta_j, M)+ \lambda \sum_{j=1}^p |\beta_j|
\]</span></p>
<p>I don’t know if there’s an actual implementation of this in an R package, but it’s easy to do with cvx.</p>
</div>
<div class="slide section level2">

<div class="incremental">
<p>Define the variable to be optimized over:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1"></a>betahat =<span class="st"> </span><span class="kw">Variable</span>(p)</span></code></pre></div>
<p>Define the objective:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1"></a>lambda =<span class="st"> </span><span class="dv">10</span><span class="op">^</span>(<span class="op">-</span><span class="dv">4</span>)</span>
<span id="cb54-2"><a href="#cb54-2"></a>objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>(<span class="kw">huber</span>(Y <span class="op">-</span><span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>betahat)) <span class="op">+</span><span class="st"> </span>lambda <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(betahat)))</span></code></pre></div>
<p>Define the problem and solve it:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1"></a>problem =<span class="st"> </span><span class="kw">Problem</span>(objective)</span>
<span id="cb55-2"><a href="#cb55-2"></a>result =<span class="st"> </span><span class="kw">solve</span>(problem)</span>
<span id="cb55-3"><a href="#cb55-3"></a><span class="kw">round</span>(result<span class="op">$</span><span class="kw">getValue</span>(betahat), <span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##       [,1]
##  [1,] 0.00
##  [2,] 0.00
##  [3,] 0.71
##  [4,] 0.00
##  [5,] 0.00
##  [6,] 0.00
##  [7,] 0.00
##  [8,] 0.00
##  [9,] 1.31
## [10,] 0.00</code></pre>
</div>
</div>
<div class="slide section level2">

<p>Searching over a grid of <span class="math inline">\(\lambda\)</span>:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1"></a>lambda_search =<span class="st"> </span><span class="dv">10</span><span class="op">^</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">-3</span>, <span class="dt">length.out =</span> <span class="dv">40</span>))</span>
<span id="cb57-2"><a href="#cb57-2"></a>get_beta_hat_lasso =<span class="st"> </span><span class="cf">function</span>(lambda) {</span>
<span id="cb57-3"><a href="#cb57-3"></a>    objective =<span class="st"> </span><span class="kw">Minimize</span>(<span class="kw">sum</span>(<span class="kw">huber</span>(Y <span class="op">-</span><span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>beta_lasso)) <span class="op">+</span><span class="st"> </span>lambda <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">abs</span>(beta_lasso)))</span>
<span id="cb57-4"><a href="#cb57-4"></a>    problem =<span class="st"> </span><span class="kw">Problem</span>(objective)</span>
<span id="cb57-5"><a href="#cb57-5"></a>    result =<span class="st"> </span><span class="kw">solve</span>(problem)</span>
<span id="cb57-6"><a href="#cb57-6"></a>    result<span class="op">$</span><span class="kw">getValue</span>(beta_lasso)</span>
<span id="cb57-7"><a href="#cb57-7"></a>}</span>
<span id="cb57-8"><a href="#cb57-8"></a>beta_hats =<span class="st"> </span>plyr<span class="op">::</span><span class="kw">aaply</span>(lambda_search, <span class="dv">1</span>, get_beta_hat_lasso)</span>
<span id="cb57-9"><a href="#cb57-9"></a><span class="kw">colnames</span>(beta_hats) =<span class="st"> </span><span class="kw">colnames</span>(diabetes<span class="op">$</span>x)</span>
<span id="cb57-10"><a href="#cb57-10"></a>beta_hats =<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">lambda =</span> lambda_search, beta_hats)</span>
<span id="cb57-11"><a href="#cb57-11"></a><span class="kw">round</span>(beta_hats, <span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##    lambda  age   sex   bmi   map    tc   ldl   hdl   tch   ltg  glu
## 1       0 3.78 -4.26 19.91 10.54 -1.45 -7.03 -2.60 11.24 17.53 4.39
## 2       0 3.78 -4.25 19.92 10.51 -0.86 -7.41 -2.96 10.97 17.34 4.42
## 3       0 3.79 -4.26 19.91 10.54 -1.46 -7.14 -2.49 11.41 17.53 4.39
## 4       0 3.76 -4.21 19.91 10.48 -1.15 -7.24 -2.71 11.15 17.45 4.39
## 5       0 3.73 -4.15 19.87 10.48 -1.18 -7.08 -2.74 11.01 17.49 4.37
## 6       0 3.71 -4.11 19.87 10.46 -0.99 -7.16 -2.84 10.90 17.44 4.36
## 7       0 3.71 -4.10 19.87 10.45 -0.60 -7.43 -3.03 10.80 17.31 4.36
## 8       0 3.69 -4.05 19.86 10.43 -0.32 -7.57 -3.17 10.67 17.22 4.35
## 9       0 3.66 -4.00 19.83 10.41 -0.99 -6.91 -2.93 10.59 17.50 4.34
## 10      0 3.65 -3.94 19.82 10.37  0.07 -7.59 -3.49 10.23 17.14 4.34
## 11      0 3.58 -3.80 19.77 10.30 -0.42 -6.85 -3.44  9.82 17.41 4.31
## 12      0 3.51 -3.66 19.73 10.23 -0.92 -6.12 -3.37  9.43 17.68 4.27
## 13      0 3.58 -3.79 19.77 10.31  0.01 -7.28 -3.50  9.95 17.20 4.31
## 14      0 3.54 -3.68 19.65 10.20 -1.23 -5.68 -3.47  9.15 17.79 4.34
## 15      0 3.39 -3.37 19.62 10.06 -1.20 -5.10 -3.69  8.36 17.96 4.24
## 16      0 3.20 -3.02 19.56  9.91 -0.42 -5.02 -4.22  7.43 17.84 4.15
## 17      0 2.99 -2.63 19.46  9.76 -0.01 -4.59 -4.59  6.47 17.86 4.05
## 18      0 1.90 -0.49 19.07  8.82  0.00 -0.60 -5.79  1.39 18.86 3.55
## 19      0 1.70 -0.01 18.95  8.58  0.00 -0.14 -5.83  0.73 18.92 3.50
## 20      0 1.85 -1.19 18.71  8.76  0.00 -0.16 -6.26  0.87 18.68 3.64
## 21      0 1.17  0.05 18.56  8.11  0.00  0.00 -5.33  0.60 18.67 3.28
## 22      0 0.00  0.00 17.52  6.76  0.00  0.00 -3.28  0.91 17.97 2.19
## 23      0 0.00  0.00 10.22  0.00  0.00  0.00  0.00  0.00 11.56 0.00
## 24      0 0.34 -0.01 17.88  7.52  0.00  0.00 -4.22  1.06 18.13 2.87
## 25      0 0.00  0.00  0.14  0.00  0.00  0.00  0.00  0.00  0.78 0.00
## 26      0 0.00  0.00  0.08  0.00  0.00  0.00  0.00  0.00  0.93 0.00
## 27      0 0.00  0.00  0.71  0.00  0.00  0.00  0.00  0.00  1.31 0.00
## 28      0 0.00  0.00  0.20  0.00  0.00  0.00  0.00  0.00  0.07 0.00
## 29      0 0.00  0.00 15.24  4.71  0.00  0.00 -0.48  2.37 15.73 1.07
## 30      0 0.00  0.00  0.37  0.00  0.00  0.00  0.00  0.00  0.11 0.00
## 31      0 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.24 0.00
## 32      0 0.00  0.00  0.02  0.00  0.00  0.00  0.00  0.00  0.02 0.00
## 33      0 0.00  0.00  0.01  0.00  0.00  0.00  0.00  0.00  0.83 0.00
## 34      0 0.00  0.00  0.01  0.00  0.00  0.00  0.00  0.00  0.41 0.00
## 35      0 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.01 0.00
## 36      0 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.01 0.00
## 37      0 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00 0.00
## 38      0 0.00  0.00  0.06  0.00  0.00  0.00  0.00  0.00  0.03 0.00
## 39      0 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00 0.00
## 40      0 0.00  0.00  0.04  0.00  0.00  0.00  0.00  0.01  0.00 0.00</code></pre>
</div>
<div class="slide section level2">

<p>Plot of the coefficients for different values of <span class="math inline">\(\lambda\)</span>:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1"></a>beta_melted =<span class="st"> </span>reshape2<span class="op">::</span><span class="kw">melt</span>(<span class="kw">data.frame</span>(beta_hats), <span class="dt">id.vars =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">value.name =</span> <span class="st">&quot;coefficient&quot;</span>)</span>
<span id="cb59-2"><a href="#cb59-2"></a><span class="kw">ggplot</span>(beta_melted) <span class="op">+</span></span>
<span id="cb59-3"><a href="#cb59-3"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lambda, <span class="dt">y =</span> coefficient, <span class="dt">color =</span> variable, <span class="dt">lty =</span> variable)) <span class="op">+</span></span>
<span id="cb59-4"><a href="#cb59-4"></a><span class="st">    </span><span class="kw">scale_x_log10</span>()</span></code></pre></div>
<p><img src="lecture-21-fig/unnamed-chunk-26-1.png" /></p>
</div>
<div id="summing-up-1" class="slide section level2">
<h1>Summing up</h1>
<ul>
<li><p>Many statistical problems and variations can be expressed as convex optimization problems.</p></li>
<li><p>These are cheap and easy to fit, and you don’t need to rely on your exact problem being implemented by someone else.</p></li>
<li><p>Cvx behind the scenes is using some of the methods that we’ve been discussing the past couple of weeks.</p></li>
</ul>
</div>
</body>
</html>
